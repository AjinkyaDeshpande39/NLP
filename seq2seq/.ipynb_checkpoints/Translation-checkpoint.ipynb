{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field,BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-d41b4e1135b8>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-d41b4e1135b8>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    but you can still load the model via its full package name: nlp =\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "but you can still load the model via its full package name: nlp =\n",
    "spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting de_core_news_sm==2.3.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.3.0/de_core_news_sm-2.3.0.tar.gz (14.9 MB)\n",
      "Requirement already satisfied: spacy<2.4.0,>=2.3.0 in c:\\programdata\\anaconda3\\envs\\project2\\lib\\site-packages (from de_core_news_sm==2.3.0) (2.3.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\programdata\\anaconda3\\envs\\project2\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (0.7.4)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in c:\\programdata\\anaconda3\\envs\\project2\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (7.4.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\programdata\\anaconda3\\envs\\project2\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (0.8.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\envs\\project2\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (3.0.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\programdata\\anaconda3\\envs\\project2\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\programdata\\anaconda3\\envs\\project2\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.0.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\programdata\\anaconda3\\envs\\project2\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\programdata\\anaconda3\\envs\\project2\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\envs\\project2\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (50.3.0.post20201006)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\programdata\\anaconda3\\envs\\project2\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (4.56.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\anaconda3\\envs\\project2\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\programdata\\anaconda3\\envs\\project2\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.19.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\envs\\project2\\lib\\site-packages (from spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.25.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\envs\\project2\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (1.26.2)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\programdata\\anaconda3\\envs\\project2\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\envs\\project2\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\programdata\\anaconda3\\envs\\project2\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<2.4.0,>=2.3.0->de_core_news_sm==2.3.0) (4.0.0)\n",
      "Building wheels for collected packages: de-core-news-sm\n",
      "  Building wheel for de-core-news-sm (setup.py): started\n",
      "  Building wheel for de-core-news-sm (setup.py): finished with status 'done'\n",
      "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.3.0-py3-none-any.whl size=14907583 sha256=11d552684b641fd46871afba59498cb4b64b2cd06036bb50069214023599f1fb\n",
      "  Stored in directory: C:\\Users\\Asus\\AppData\\Local\\Temp\\pip-ephem-wheel-cache-b6uqk0wd\\wheels\\5d\\ea\\e9\\0d432e5114b7cba534bb0742b7de51e03db174dfb1e3dda87c\n",
      "Successfully built de-core-news-sm\n",
      "Installing collected packages: de-core-news-sm\n",
      "Successfully installed de-core-news-sm-2.3.0\n",
      "[+] Download and installation successful\n",
      "You can now load the model via spacy.load('de_core_news_sm')\n",
      "[x] Couldn't link model to 'de'\n",
      "Creating a symlink in spacy/data failed. Make sure you have the required\n",
      "permissions and try re-running the command as admin, or use a virtualenv. You\n",
      "can still import the model as a module and call its load() method, or create the\n",
      "symlink manually.\n",
      "C:\\ProgramData\\Anaconda3\\envs\\project2\\lib\\site-packages\\de_core_news_sm -->\n",
      "C:\\ProgramData\\Anaconda3\\envs\\project2\\lib\\site-packages\\spacy\\data\\de\n",
      "[!] Download successful but linking failed\n",
      "Creating a shortcut link for 'de' didn't work (maybe you don't have admin\n",
      "permissions?), but you can still load the model via its full package name: nlp =\n",
      "spacy.load('de_core_news_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You do not have sufficient privilege to perform this operation.\n"
     ]
    }
   ],
   "source": [
    "but you can still load the model via its full package name: nlp =\n",
    "spacy.load('de_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_eng = spacy.load('en_core_web_sm')\n",
    "spacy_ger = spacy.load('de_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_eng(text):\n",
    "    return([tok.text for tok in spacy_eng.tokenizer(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_ger(text):\n",
    "    return([tok.text for tok in spacy_ger.tokenizer(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\project2\\lib\\site-packages\\torchtext\\data\\field.py:150: UserWarning: Field class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "english = Field(sequential=True, use_vocab=True, tokenize=tokenize_eng, lower=True,init_token='<sos>',eos_token='<eos>')\n",
    "german = Field(sequential=True, use_vocab=True, tokenize=tokenize_ger, lower=True,init_token='<sos>',eos_token='<eos>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\project2\\lib\\site-packages\\torchtext\\data\\example.py:78: UserWarning: Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('Example class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.', UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train_data, validation_data, test_data = Multi30k.splits(exts=('.de','.en'),fields=(german,english))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "english.build_vocab(train_data,max_size=10000,min_freq=2)\n",
    "german.build_vocab(train_data,max_size=10000,min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\project2\\lib\\site-packages\\torchtext\\data\\iterator.py:48: UserWarning: BucketIterator class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    }
   ],
   "source": [
    "train_iterator, validation_iterator, test_iterator = BucketIterator.splits((train_data,validation_data,test_data),\n",
    "                                                                          batch_size=128, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 33x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 33x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 35x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 36x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 38x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 33x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 34x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 36x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 33x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 36x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 25x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 38x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 37x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 25x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 36x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 41x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 42x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 25x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 34x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 35x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 34x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 23x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 25x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 37x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 40x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 34x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 33x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 34x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 34x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 34x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 23x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 24x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 38x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 37x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 40x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 37x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 36x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 34x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 33x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 36x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 37x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 36x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 38x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 25x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 36x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 33x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 35x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 35x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 40x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 34x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 41x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 33x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 35x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 25x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 35x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 38x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 37x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 33x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 25x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 33x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 36x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 37x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 33x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 24x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 33x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 34x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 25x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 25x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 25x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 34x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 33x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 34x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 37x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 33x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 39x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 35x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 35x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 45x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 42x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 25x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 24x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 25x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 24x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 25x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 33x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 33x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 34x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 25x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 24x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 33x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 24x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 33x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 45x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 41x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 34x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 33x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 33x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 25x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 38x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 36x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 34x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 24x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 24x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 37x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 36x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 46x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 37x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 25x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 24x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 33x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 25x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 33x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 34x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 40x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 36x128 (GPU 0)]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 25x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 37x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 35x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 25x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 25x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 37x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 36x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 38x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 37x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 25x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 34x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 24x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 36x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 37x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 23x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 25x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 25x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 26x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 38x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 37x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 34x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 38x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 36x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 36x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 43x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 25x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 24x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 72 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 27x72 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 28x72 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 33x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 35x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 33x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 32x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 27x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 30x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 29x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 25x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 28x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 31x128 (GPU 0)]\n",
      "\n",
      "[torchtext.data.batch.Batch of size 128 from MULTI30K]\n",
      "\t[.src]:[torch.cuda.LongTensor of size 35x128 (GPU 0)]\n",
      "\t[.trg]:[torch.cuda.LongTensor of size 37x128 (GPU 0)]\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iterator:\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\project2\\lib\\site-packages\\torchtext\\data\\batch.py:23: UserWarning: Batch class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.\n",
      "  warnings.warn('{} class will be retired in the 0.8.0 release and moved to torchtext.legacy. Please see 0.7.0 release notes for further information.'.format(self.__class__.__name__), UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "tensor([[  2,   2,   2,  ...,   2,   2,   2],\n",
      "        [  9,   4,   4,  ...,   4,   4,   4],\n",
      "        [ 13, 198,  26,  ...,  33, 667,   9],\n",
      "        ...,\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1],\n",
      "        [  1,   1,   1,  ...,   1,   1,   1]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer tensors of a single element can be converted to an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-1a8c21c8e09f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menglish\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[0mflag\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "flag=0\n",
    "for batch in train_iterator:\n",
    "    if(i<0):\n",
    "        i+=1\n",
    "        continue\n",
    "    else:\n",
    "        i+=1\n",
    "    a = batch.src\n",
    "    b = batch.trg\n",
    "    print(len(b))\n",
    "    print(b)\n",
    "    for k in b:\n",
    "        print(english.vocab.itos[k],end=\" \")    \n",
    "    flag=1\n",
    "    \n",
    "    if flag==1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english.vocab.stoi['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english.vocab.itos[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5893\n",
      "7854\n"
     ]
    }
   ],
   "source": [
    "print(len(english.vocab))\n",
    "print(len(german.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227\n"
     ]
    }
   ],
   "source": [
    "print(len(train_iterator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding,hidden_size,num_layers):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding = embedding\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size,embedding)\n",
    "        self.lstm = nn.LSTM(embedding,hidden_size,batch_first=True,num_layers=num_layers)\n",
    "        \n",
    "    def forward(self,x,hidden,cell):\n",
    "        x = self.embedding(x)\n",
    "        x = x.reshape(1,x.shape[0],x.shape[1])\n",
    "        x,(hidden,cell) = self.lstm(x,(hidden,cell))\n",
    "        return(x,(hidden,cell))\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return(torch.zeros([self.num_layers,1,self.hidden_size]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,vocab_size,embedding,hidden_size,output_size,num_layers):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding = embedding\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.embedding = nn.Embedding(vocab_size,embedding)\n",
    "        self.lstm = nn.LSTM(embedding,hidden_size,batch_first=True,num_layers=num_layers)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(hidden_size,output_size)\n",
    "        \n",
    "    def forward(self,x,hidden,cell):\n",
    "        x = self.embedding(x)\n",
    "        x = x.reshape(1,x.shape[0],x.shape[1])\n",
    "        x,(hidden,cell) = self.lstm(x,(hidden,cell))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        return(x,(hidden,cell))\n",
    "        \n",
    "    def initHidden(self):\n",
    "        return(torch.zeros([self.num_layers,1,self.hidden_size]).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Translate(nn.Module):\n",
    "    def __init__(self,encoder,decoder,output_size):\n",
    "        super(Translate,self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def forward(self,source,target,hidden,cell):    \n",
    "        \n",
    "        out,(hidden,cell) = self.encoder(source,hidden,cell)\n",
    "        out,(hidden,cell) = self.decoder(target[:-1],hidden,cell)\n",
    "        \n",
    "        return(out,hidden,cell)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_vocab_size = len(english.vocab)\n",
    "german_vocab_size = len(german.vocab)\n",
    "embedding = 100\n",
    "output_size = german_vocab_size\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "learning_rate = 0.005 \n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(german_vocab_size,embedding,hidden_size,num_layers)\n",
    "decoder = Decoder(english_vocab_size,embedding,hidden_size,output_size,num_layers)\n",
    "model = Translate(encoder,decoder,output_size).to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,887,578 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................................................................................................................................................................................................................\n",
      "mean epoch loss : 2.8971114620128366  ||  time : 366.3990890979767\n",
      "...................................................................................................................................................................................................................................\n",
      "mean epoch loss : 2.7261340483332535  ||  time : 241.05970311164856\n",
      "...................................................................................................................................................................................................................................\n",
      "mean epoch loss : 2.707842618307765  ||  time : 252.00643515586853\n",
      "...................................................................................................................................................................................................................................\n",
      "mean epoch loss : 2.6957360800186567  ||  time : 244.77276968955994\n",
      "...................................................................................................................................................................................................................................\n",
      "mean epoch loss : 2.699882499779355  ||  time : 243.995867729187\n"
     ]
    }
   ],
   "source": [
    "loss_lst = []\n",
    "temp = 0\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = []\n",
    "    t1 = time.time()\n",
    "    for batch in train_iterator:\n",
    "        t11 = time.time()\n",
    "        batch_loss = []\n",
    "        source = batch.src\n",
    "        target = batch.trg\n",
    "        for i,j in zip(source,target):\n",
    "            hidden = encoder.initHidden().to(device)\n",
    "            cell = encoder.initHidden().to(device)\n",
    "            model.zero_grad()\n",
    "            optimizer.zero_grad()\n",
    "            out,hidden,cell = model(i,j,hidden,cell)\n",
    "            \n",
    "            out = out.reshape(-1,output_size)\n",
    "            loss = criterion(out,j[1:])\n",
    "            batch_loss.append(loss.item())\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        epoch_loss += batch_loss\n",
    "        temp+=1\n",
    "        t22 = time.time()\n",
    "        #print(\"batch loss : {}  ||  time : {}\".format(np.mean(batch_loss),t22-t11))\n",
    "        \n",
    "        print(\".\",end=\"\")\n",
    "    loss_lst += epoch_loss\n",
    "    t2 = time.time()\n",
    "    print()\n",
    "    print(\"mean epoch loss : {}  ||  time : {}\".format(np.mean(epoch_loss),t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'translate_1.pth')  # translate_1.pth loss e1:2.9 e5:2.69 time per epoch : 250sec \n",
    "#lr=0.005, layer=2, embedding=100, hidden=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1908e149a90>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean epoch loss : 2.9677913672381586  ||  time : 271.4633343219757\n",
      "mean epoch loss : 2.961230300718339  ||  time : 252.48211121559143\n",
      "mean epoch loss : 3.19313870198101  ||  time : 260.6325652599335\n",
      "mean epoch loss : 5.312656619672817  ||  time : 266.6806802749634\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-5458e06442bd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mhidden\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitHidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0mcell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitHidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m             \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\project2\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36mzero_grad\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1319\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m                 \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m                 \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1322\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1323\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mshare_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
