{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = np.loadtxt('dino_names.txt',dtype='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aegyptosaurus\n",
      "Aeolosaurus\n",
      "Aepisaurus\n",
      "Aepyornithomimus\n",
      "Aerosteon\n",
      "AetonyxAfromimus\n",
      "Afrovenator\n",
      "Agathaumas\n",
      "Aggiosaurus\n",
      "Agilisaurus\n",
      ".\n",
      ".\n",
      ".\n",
      "(1536,)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "for i in range(20,30):\n",
    "    print(names[i])\n",
    "print('.\\n.\\n.')\n",
    "print(names.shape)\n",
    "print(type(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabets = {'a':1,'b':2,'c':3,'d':4,'e':5,'f':6,'g':7,'h':8,'i':9,'j':10,'k':11,'l':12,'m':13,'n':14,'o':15,'p':16,'q':17,\n",
    "            'r':18,'s':19,'t':20,'u':21,'v':22,'w':23,'x':24,'y':25,'z':26,'.':27}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'a',\n",
       " 2: 'b',\n",
       " 3: 'c',\n",
       " 4: 'd',\n",
       " 5: 'e',\n",
       " 6: 'f',\n",
       " 7: 'g',\n",
       " 8: 'h',\n",
       " 9: 'i',\n",
       " 10: 'j',\n",
       " 11: 'k',\n",
       " 12: 'l',\n",
       " 13: 'm',\n",
       " 14: 'n',\n",
       " 15: 'o',\n",
       " 16: 'p',\n",
       " 17: 'q',\n",
       " 18: 'r',\n",
       " 19: 's',\n",
       " 20: 't',\n",
       " 21: 'u',\n",
       " 22: 'v',\n",
       " 23: 'w',\n",
       " 24: 'x',\n",
       " 25: 'y',\n",
       " 26: 'z',\n",
       " 27: '.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_alphabets={}\n",
    "for i in alphabets:\n",
    "    rev_alphabets[alphabets[i]] = i\n",
    "\n",
    "rev_alphabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encodings(word,alphabets):\n",
    "    op_word = word[1:] + '.'\n",
    "    l = len(word)\n",
    "    ip_word_enc = torch.zeros([l,28])\n",
    "    op_word_enc = torch.zeros([l])\n",
    "    \n",
    "    for i in range(l):\n",
    "        ip_word_enc[i,alphabets[word[i]]] = 1\n",
    "        op_word_enc[i] = alphabets[op_word[i]]\n",
    "    \n",
    "    return(ip_word_enc,op_word_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.,  3.,  8.,  5., 14., 15., 19.,  1., 21., 18., 21., 19., 27.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a,b = encodings(names[0].lower(),alphabets)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super(RNN,self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size+hidden_size,hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size,output_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.LogSoftmax()                # not using softmax because we are using CrossEntropyLoss\n",
    "    \n",
    "    def forward(self,z):\n",
    "        hidden = self.fc1(z)\n",
    "        hidden = self.tanh(hidden)\n",
    "        output = self.fc2(hidden)\n",
    "        #output = self.softmax(output)                 # \n",
    "        \n",
    "        \n",
    "        return(hidden,output)\n",
    "    \n",
    "    def initHidden(self,hidden_size):\n",
    "        return(torch.zeros([1,hidden_size]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 64\n",
    "input_size = 28\n",
    "output_size = 28\n",
    "learning_rate = 0.02      # learning rate was reduced to 0.00515\n",
    "num_epochs = 24           # with total epoch 24 , i have reached epoch_loss = 1.433 (saturating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RNN(input_size,hidden_size,output_size).to(device)     #sending model to device(cuda) hoping it would save time\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=learning_rate)    #useless :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch loss: 1.3210315432328492  |  time: 75.49013066291809 sec  |  mean loss till now: 1.4473915847061913\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-fdcea6d3df65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0ml\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m             \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m                                \u001b[1;31m#Use retain_graph=True else it will stuck\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m                                 \u001b[1;31m#Instead of optimizer.step() we are updating parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\project2\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\project2\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 125\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#loss_list = []\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    t1 = time.time()\n",
    "    epoch_loss=[]\n",
    "    learning_rate = learning_rate*0.98\n",
    "    for word in names:\n",
    "        loss = 0\n",
    "        ip_word_enc, op_word_enc = encodings(word.lower(),alphabets)\n",
    "        ip_word_enc = ip_word_enc.to(device)                          #passing ip_word_enc to device now itself saves time rather\n",
    "        op_word_enc = op_word_enc.to(device)                          # than passing each letter and target individualy\n",
    "        \n",
    "        hidden = model.initHidden(hidden_size)\n",
    "        hidden = hidden.to(device)\n",
    "        \n",
    "        for letter,target in zip(ip_word_enc,op_word_enc):\n",
    "            letter = letter.reshape(1,-1)\n",
    "            target = target.reshape(1).long()\n",
    "            \n",
    "            z = torch.cat((letter,hidden),1)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            model.zero_grad()\n",
    "            hidden,output = model(z)\n",
    "            \n",
    "            l = criterion(output,target)\n",
    "            loss += l.item()\n",
    "            l.backward(retain_graph=True)                                #Use retain_graph=True else it will stuck\n",
    "        \n",
    "            for p in model.parameters():                                 #Instead of optimizer.step() we are updating parameters\n",
    "                p.data.add_(p.grad.data, alpha=-learning_rate)           # in this way\n",
    "            \n",
    "        epoch_loss.append(loss/len(word))\n",
    "    loss_list += epoch_loss\n",
    "    t2 = time.time()\n",
    "    print(\"epoch loss:\",np.mean(epoch_loss),\" |  time:\",t2-t1,\"sec\",\" |  mean loss till now:\",np.mean(loss_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x22683276cd0>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'CharLevelRNN2_2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = learning_rate*0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0009603999999999999"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (fc1): Linear(in_features=92, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=28, bias=True)\n",
       "  (tanh): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.load_state_dict(torch.load('CharLevelRNN2_2.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generating names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(a):\n",
    "\n",
    "    a_enc = torch.zeros([1,28])\n",
    "\n",
    "    a_enc[0,alphabets[a]] = 1\n",
    "    hidden = model.initHidden(hidden_size)\n",
    "    z = torch.cat((a_enc,hidden),1).to(device)\n",
    "    hidden,out = model(z.to(device))\n",
    "    #new_letter_enc = torch.tensor(out>=out.max(),dtype=int)\n",
    "    letter = rev_alphabets[torch.argmax(out).item()]\n",
    "    #print(out)\n",
    "    out = F.softmax(out,dim=1)\n",
    "    #print(out)\n",
    "    a += letter\n",
    "\n",
    "    while letter!='.':\n",
    "        z = torch.cat((out,hidden),1).to(device)\n",
    "        hidden,out = model(z.to(device))\n",
    "        #new_letter_enc = torch.tensor(out>=out.max(),dtype=int)\n",
    "        letter = rev_alphabets[torch.argmax(out).item()]\n",
    "        out = F.softmax(out,dim=1)\n",
    "        #print(out)\n",
    "        a += letter\n",
    "    return(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for a : ausarasaurus.\n",
      "for b : branantasaurus.\n",
      "for c : crypaneoshosaur.\n",
      "for d : drpsansasaus.\n",
      "for e : euaaausaneasts.\n",
      "for f : fanaaeaanaas.\n",
      "for g : grapanasaurus.\n",
      "for h : hapsitasaarus.\n",
      "for i : isnasauaus.\n",
      "for j : jaranananroisas.\n",
      "for k : kanparasaurus.\n",
      "for l : lapaalasaseus.\n",
      "for m : mantacanatous.\n",
      "for n : napnanastis.\n",
      "for o : ostapasaurus.\n",
      "for p : preatasaaaus.\n",
      "for q : quaeamasatsaa.\n",
      "for r : rapaaorasnus.\n",
      "for s : sanpatanaa.\n",
      "for t : tatanasaasae.\n",
      "for u : ustestuaanas.\n",
      "for v : vanaalasaurus.\n",
      "for w : wanaalasaurus.\n",
      "for x : xinualaanesas.\n",
      "for y : yangansaneuss.\n",
      "for z : zapaaaaaaeaus.\n"
     ]
    }
   ],
   "source": [
    "for i in alphabets:\n",
    "    if i=='.':\n",
    "        continue\n",
    "    word = generate(i)\n",
    "    print(\"for {} : {}\".format(i,word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for a : anaosataurus.\n",
      "for b : brrcolosenis.\n",
      "for c : crenocoeaeus.\n",
      "for d : deooaephiaeus.\n",
      "for e : euaocosasnes.\n",
      "for f : fencaaosanatras.\n",
      "for g : gongcuoaeeos.\n",
      "for h : hualitosauau.\n",
      "for i : inoosauau.\n",
      "for j : jiansloanisaus.\n",
      "for k : kunhorosanaalus.\n",
      "for l : locoolaeieta.\n",
      "for m : manoaaanessus.\n",
      "for n : nateoaaanatas.\n",
      "for o : ornatosaneaa.\n",
      "for p : proarosaurus.\n",
      "for q : qiaeialanasaus.\n",
      "for r : riouariaeiaeu.\n",
      "for s : stlnenosasus.\n",
      "for t : tiaonocaeuesaurus.\n",
      "for u : ustrslaaiue.\n",
      "for v : velenosausaste.\n",
      "for w : walaerosaurus.\n",
      "for x : xiahosauais.\n",
      "for y : yunoratasiu.\n",
      "for z : zhunoacoalenau.\n"
     ]
    }
   ],
   "source": [
    "for i in alphabets:\n",
    "    if i=='.':\n",
    "        continue\n",
    "    word = generate(i)\n",
    "    print(\"for {} : {}\".format(i,word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protecovasaurus\n",
      "Protiguanodon\n",
      "Protoavis\n",
      "Protoceratops\n",
      "Protognathosaurus\n",
      "Protognathus\n",
      "Protohadros\n",
      "Protorosaurus\n",
      "Protorosaurus\n",
      "Protrachodon\n",
      "Proyandusaurus\n",
      "Pseudolagosuchus\n",
      "Psittacosaurus\n",
      "Pteropelyx\n",
      "Pterospondylus\n",
      "Puertasaurus\n",
      "Pukyongosaurus\n",
      "Pulanesaura\n",
      "Pycnonemosaurus\n",
      "Pyroraptor\n",
      "Qantassaurus\n",
      "Qianzhousaurus\n",
      "Qiaowanlong\n",
      "Qijianglong\n",
      "Qinlingosaurus\n",
      "Qingxiusaurus\n",
      "Qiupalong\n",
      "Quaesitosaurus\n",
      "Quetecsaurus\n",
      "Quilmesaurus\n",
      "Rachitrema\n",
      "Rahiolisaurus\n",
      "Rahona\n",
      "Rahonavis\n",
      "Rajasaurus\n",
      "Rapator\n",
      "Rapetosaurus\n",
      "Raptorex\n",
      "Ratchasimasaurus\n",
      "Rativates\n",
      "Rayososaurus\n",
      "Razanandrongobe\n",
      "Rebbachisaurus\n",
      "Regaliceratops\n",
      "Regnosaurus\n",
      "Revueltosaurus\n",
      "Rhabdodon\n",
      "Rhadinosaurus\n",
      "Rhinorex\n",
      "Rhodanosaurus\n",
      "Rhoetosaurus\n",
      "Rhopalodon\n",
      "Riabininohadros\n",
      "Richardoestesia\n",
      "Rileya\n",
      "Rileyasuchus\n",
      "Rinchenia\n",
      "Rinconsaurus\n",
      "Rioarribasaurus\n",
      "Riodevasaurus\n",
      "Riojasaurus\n",
      "Riojasuchus\n",
      "Rocasaurus\n",
      "Roccosaurus\n",
      "Rubeosaurus\n",
      "Ruehleia\n",
      "Rugocaudia\n",
      "Rugops\n",
      "Rukwatitan\n",
      "Ruyangosaurus\n",
      "Sacisaurus\n",
      "Sahaliyania\n",
      "Saichania\n",
      "Saldamosaurus\n",
      "Salimosaurus\n",
      "Saltasaurus\n",
      "Saltopus\n",
      "Saltriosaurus\n",
      "Sanchusaurus\n",
      "Sangonghesaurus\n",
      "Sanjuansaurus\n",
      "Sanpasaurus\n",
      "Santanaraptor\n",
      "Saraikimasoom\n",
      "Sarahsaurus\n",
      "Sarcolestes\n",
      "Sarcosaurus\n",
      "Sarmientosaurus\n",
      "Saturnalia\n",
      "Sauraechinodon\n",
      "Saurolophus\n",
      "Sauroniops\n",
      "Sauropelta\n",
      "Saurophaganax\n",
      "Saurophagus\n",
      "Sauroplites\n",
      "Sauroposeidon\n",
      "Saurornithoides\n",
      "Saurornitholestes\n",
      "Savannasaurus\n",
      "Scansoriopteryx\n",
      "Scaphonyx\n",
      "Scelidosaurus\n",
      "Scipionyx\n",
      "Sciurumimus\n",
      "Scleromochlus\n",
      "Scolosaurus\n",
      "Scutellosaurus\n",
      "Secernosaurus\n",
      "Sefapanosaurus\n",
      "Segisaurus\n",
      "Segnosaurus\n",
      "Seismosaurus\n",
      "Seitaad\n",
      "Selimanosaurus\n",
      "Sellacoxa\n",
      "Sellosaurus\n",
      "Serendipaceratops\n",
      "Serikornis\n",
      "Shamosaurus\n",
      "Shanag\n",
      "Shanshanosaurus\n",
      "Shantungosaurus\n",
      "Shanxia\n",
      "Shanyangosaurus\n",
      "Shaochilong\n",
      "Shenzhousaurus\n",
      "Shidaisaurus\n",
      "Shingopana\n",
      "Shixinggia\n",
      "Shuangbaisaurus\n",
      "Shuangmiaosaurus\n",
      "Shunosaurus\n",
      "Shuvosaurus\n",
      "Shuvuuia\n",
      "Siamodon\n",
      "Siamodracon\n",
      "Siamosaurus\n",
      "Siamotyrannus\n",
      "Siats\n",
      "Sibirosaurus\n",
      "Sibirotitan\n",
      "Sidormimus\n",
      "Sigilmassasaurus\n",
      "Silesaurus\n",
      "Siluosaurus\n",
      "Silvisaurus\n",
      "Similicaudipteryx\n",
      "Sinocalliopteryx\n",
      "Sinoceratops\n",
      "Sinocoelurus\n",
      "Sinopelta\n",
      "Sinopeltosaurus\n",
      "Sinornithoides\n",
      "Sinornithomimus\n",
      "Sinornithosaurus\n",
      "Sinosauropteryx\n",
      "Sinosaurus\n",
      "Sinotyrannus\n",
      "Sinovenator\n",
      "Sinraptor\n",
      "Sinusonasus\n",
      "Sirindhorna\n",
      "Skorpiovenator\n",
      "Smilodon\n",
      "Sonidosaurus\n",
      "Sonorasaurus\n",
      "Soriatitan\n",
      "Sphaerotholus\n",
      "Sphenosaurus\n",
      "Sphenospondylus\n",
      "Spiclypeus\n",
      "Spinophorosaurus\n",
      "Spinops\n",
      "Spinosaurus\n",
      "Spinostropheus\n",
      "Spinosuchus\n",
      "Spondylosoma\n",
      "Squalodon\n",
      "Staurikosaurus\n",
      "Stegoceras\n",
      "Stegopelta\n",
      "Stegosaurides\n",
      "Stegosaurus\n",
      "Stenonychosaurus\n",
      "Stenopelix\n",
      "Stenotholus\n",
      "Stephanosaurus\n",
      "Stereocephalus\n",
      "Sterrholophus\n",
      "Stokesosaurus\n",
      "Stormbergia\n",
      "Strenusaurus\n",
      "Streptospondylus\n",
      "Struthiomimus\n",
      "Struthiosaurus\n",
      "Stygimoloch\n",
      "Stygivenator\n",
      "Styracosaurus\n",
      "Succinodon\n",
      "Suchomimus\n",
      "Suchosaurus\n",
      "Suchoprion\n",
      "Sugiyamasaurus\n",
      "Skeleton\n",
      "Sulaimanisaurus\n",
      "Supersaurus\n",
      "Suuwassea\n",
      "Suzhousaurus\n",
      "Symphyrophus\n",
      "Syngonosaurus\n",
      "Syntarsus\n",
      "Syrmosaurus\n",
      "Szechuanosaurus\n",
      "Tachiraptor\n",
      "Talarurus\n",
      "Talenkauen\n",
      "Talos\n",
      "Tambatitanis\n",
      "Tangvayosaurus\n",
      "Tanius\n",
      "Tanycolagreus\n",
      "Tanystropheus\n",
      "Tanystrosuchus\n",
      "Taohelong\n",
      "Tapinocephalus\n",
      "Tapuiasaurus\n",
      "Tarascosaurus\n",
      "Tarbosaurus\n",
      "Tarchia\n",
      "Tastavinsaurus\n",
      "Tatankacephalus\n",
      "Tatankaceratops\n",
      "Tataouinea\n",
      "Tatisaurus\n",
      "Taurovenator\n",
      "Taveirosaurus\n",
      "Tawa\n",
      "Tawasaurus\n",
      "Tazoudasaurus\n",
      "Technosaurus\n",
      "Tecovasaurus\n",
      "Tehuelchesaurus\n",
      "Teihivenator\n",
      "Teinurosaurus\n",
      "Teleocrater\n",
      "Telmatosaurus\n",
      "Tenantosaurus\n",
      "Tenchisaurus\n",
      "Tendaguria\n",
      "Tengrisaurus\n",
      "Tenontosaurus\n",
      "Teratophoneus\n",
      "Teratosaurus\n",
      "Termatosaurus\n",
      "Tethyshadros\n",
      "Tetragonosaurus\n",
      "Texacephale\n",
      "Texasetes\n",
      "Teyuwasu\n",
      "Thecocoelurus\n",
      "Thecodontosaurus\n",
      "Thecospondylus\n",
      "Theiophytalia\n",
      "Therizinosaurus\n",
      "Therosaurus\n",
      "Thescelosaurus\n",
      "Thespesius\n",
      "Thotobolosaurus\n",
      "Tianchisaurus\n",
      "Tianchungosaurus\n",
      "Tianyulong\n",
      "Tianyuraptor\n",
      "Tianzhenosaurus\n",
      "Tichosteus\n",
      "Tienshanosaurus\n",
      "Timimus\n",
      "Timurlengia\n",
      "Titanoceratops\n",
      "Titanosaurus\n",
      "Titanosaurus\n",
      "Tochisaurus\n",
      "Tomodon\n",
      "Tonganosaurus\n",
      "Tongtianlong\n",
      "Tonouchisaurus\n",
      "Torilion\n",
      "Tornieria\n",
      "Torosaurus\n",
      "Torvosaurus\n",
      "Tototlmimus\n",
      "Trachodon\n",
      "Traukutitan\n",
      "Trialestes\n",
      "Triassolestes\n",
      "Tribelesodon\n",
      "Triceratops\n",
      "Trigonosaurus\n",
      "Trimucrodon\n",
      "Trinisaura\n",
      "Triunfosaurus\n",
      "Troodon\n",
      "Tsaagan\n",
      "Tsagantegia\n",
      "Tsintaosaurus\n",
      "Tugulusaurus\n",
      "Tuojiangosaurus\n",
      "Turanoceratops\n",
      "Turiasaurus\n",
      "Tylocephale\n",
      "Tylosteus\n",
      "Tyrannosaurus\n",
      "Tyrannotitan\n",
      "Illustration\n",
      "Uberabatitan\n",
      "Udanoceratops\n",
      "Ugrosaurus\n",
      "Ugrunaaluk\n",
      "Uintasaurus\n",
      "Ultrasauros\n",
      "Ultrasaurus\n",
      "Ultrasaurus\n",
      "Umarsaurus\n",
      "Unaysaurus\n",
      "Unenlagia\n",
      "Unescoceratops\n",
      "Unicerosaurus\n",
      "Unquillosaurus\n",
      "Urbacodon\n",
      "Utahceratops\n",
      "Utahraptor\n",
      "Uteodon\n",
      "Vagaceratops\n",
      "Vahiny\n",
      "Valdoraptor\n",
      "Valdosaurus\n",
      "Variraptor\n",
      "Velociraptor\n",
      "Vectensia\n",
      "Vectisaurus\n",
      "Velafrons\n",
      "Velocipes\n",
      "Velociraptor\n",
      "Velocisaurus\n",
      "Venaticosuchus\n",
      "Venenosaurus\n",
      "Veterupristisaurus\n",
      "Viavenator\n",
      "Vitakridrinda\n",
      "Vitakrisaurus\n",
      "Volkheimeria\n",
      "Vouivria\n",
      "Vulcanodon\n",
      "Wadhurstia\n",
      "Wakinosaurus\n",
      "Walgettosuchus\n",
      "Walkeria\n",
      "Walkersaurus\n",
      "Wangonisaurus\n",
      "Wannanosaurus\n",
      "Wellnhoferia\n",
      "Wendiceratops\n",
      "Wiehenvenator\n",
      "Willinakaqe\n",
      "Wintonotitan\n",
      "Wuerhosaurus\n",
      "Wulagasaurus\n",
      "Wulatelong\n",
      "Wyleyia\n",
      "Wyomingraptor\n",
      "Xenoceratops\n",
      "Xenoposeidon\n",
      "Xenotarsosaurus\n",
      "Xianshanosaurus\n",
      "Xiaosaurus\n",
      "Xingxiulong\n",
      "Xinjiangovenator\n",
      "Xinjiangtitan\n",
      "Xiongguanlong\n",
      "Xixianykus\n",
      "Xixiasaurus\n",
      "Xixiposaurus\n",
      "Xuanhanosaurus\n",
      "Xuanhuaceratops\n",
      "Xuanhuasaurus\n",
      "Xuwulong\n",
      "Yaleosaurus\n",
      "Yamaceratops\n",
      "Yandusaurus\n",
      "Yangchuanosaurus\n",
      "Yaverlandia\n",
      "Yehuecauhceratops\n",
      "Yezosaurus\n",
      "Yibinosaurus\n",
      "Yimenosaurus\n",
      "Yingshanosaurus\n",
      "Yinlong\n",
      "Yixianosaurus\n",
      "Yizhousaurus\n",
      "Yongjinglong\n",
      "Yuanmouraptor\n",
      "Yuanmousaurus\n",
      "Yueosaurus\n",
      "Yulong\n",
      "Yunganglong\n",
      "Yunmenglong\n",
      "Yunnanosaurus\n",
      "Yunxianosaurus\n",
      "Yurgovuchia\n",
      "Yutyrannus\n",
      "Zanabazar\n",
      "Zanclodon\n",
      "Zapalasaurus\n",
      "Zapsalis\n",
      "Zaraapelta\n",
      "ZatomusZby\n",
      "Zephyrosaurus\n",
      "Zhanghenglong\n",
      "Zhejiangosaurus\n",
      "Zhenyuanlong\n",
      "Zhongornis\n",
      "Zhongjianosaurus\n",
      "Zhongyuansaurus\n",
      "Zhuchengceratops\n",
      "Zhuchengosaurus\n",
      "Zhuchengtitan\n",
      "Zhuchengtyrannus\n",
      "Ziapelta\n",
      "Zigongosaurus\n",
      "Zizhongosaurus\n",
      "Zuniceratops\n",
      "Zunityrannus\n",
      "Zuolong\n",
      "Zuoyunlong\n",
      "Zupaysaurus\n",
      "Zuul\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1536 is out of bounds for axis 0 with size 1536",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-72-9eed4930253e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m: index 1536 is out of bounds for axis 0 with size 1536"
     ]
    }
   ],
   "source": [
    "for i in range(1100,2000):\n",
    "    print(names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
