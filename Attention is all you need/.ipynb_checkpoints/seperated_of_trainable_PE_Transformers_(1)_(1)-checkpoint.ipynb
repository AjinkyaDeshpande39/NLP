{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention is all you need\n",
    "## Transformers from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing some libraries and dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BRX8eJ8fgg0E",
    "outputId": "119405a2-014c-4feb-9b56-f0f8650e77c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchtext==0.6.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f2/17/e7c588245aece7aa93f360894179374830daf60d7ed0bbb59332de3b3b61/torchtext-0.6.0-py3-none-any.whl (64kB)\n",
      "\r",
      "\u001b[K     |█████                           | 10kB 18.6MB/s eta 0:00:01\r",
      "\u001b[K     |██████████▏                     | 20kB 26.2MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████▎                | 30kB 23.6MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████▍           | 40kB 17.7MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▌      | 51kB 10.5MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▋ | 61kB 11.9MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 71kB 6.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.8.1+cu101)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.19.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (1.15.0)\n",
      "Collecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2MB 12.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (2.23.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.6.0) (4.41.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchtext==0.6.0) (3.7.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2020.12.5)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.6.0) (3.0.4)\n",
      "Installing collected packages: sentencepiece, torchtext\n",
      "  Found existing installation: torchtext 0.9.1\n",
      "    Uninstalling torchtext-0.9.1:\n",
      "      Successfully uninstalled torchtext-0.9.1\n",
      "Successfully installed sentencepiece-0.1.95 torchtext-0.6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import spacy\n",
    "!pip install torchtext==0.6.0\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field,BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ccLfwus9gwQL",
    "outputId": "e237b7fc-4844-4c8e-fc37-e96710f89899",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: en_core_web_sm==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 in /usr/local/lib/python3.7/dist-packages (2.2.5)\n",
      "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.41.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.8.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (54.2.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.8.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.4.3)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n",
      "/usr/local/lib/python3.7/dist-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n",
      "Collecting de_core_news_sm==2.2.5\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
      "\u001b[K     |████████████████████████████████| 14.9MB 7.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.19.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (54.2.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.5)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.12.5)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.8.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.4.1)\n",
      "Building wheels for collected packages: de-core-news-sm\n",
      "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp37-none-any.whl size=14907057 sha256=7384beaecc7988f79b2c4479c7d4ce077e5c70289e7df9c8245705aede8f9b83\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-p10l345j/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
      "Successfully built de-core-news-sm\n",
      "Installing collected packages: de-core-news-sm\n",
      "Successfully installed de-core-news-sm-2.2.5\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('de_core_news_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/usr/local/lib/python3.7/dist-packages/de_core_news_sm -->\n",
      "/usr/local/lib/python3.7/dist-packages/spacy/data/de\n",
      "You can now load the model via spacy.load('de')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en\n",
    "!python -m spacy download de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7MSsjy0YgyJg"
   },
   "outputs": [],
   "source": [
    "spacy_eng = spacy.load('en')\n",
    "spacy_ger = spacy.load('de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zhnTzZCJg6q6"
   },
   "outputs": [],
   "source": [
    "def tokenize_eng(text):\n",
    "    return([tok.text for tok in spacy_eng.tokenizer(text)])\n",
    "def tokenize_ger(text):\n",
    "    return([tok.text for tok in spacy_ger.tokenizer(text)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9flo9Puag_bS",
    "outputId": "1b12606b-66a3-479f-d16a-79fba22c7c1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading training.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "training.tar.gz: 100%|██████████| 1.21M/1.21M [00:02<00:00, 559kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading validation.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "validation.tar.gz: 100%|██████████| 46.3k/46.3k [00:00<00:00, 169kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading mmt_task1_test2016.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mmt_task1_test2016.tar.gz: 100%|██████████| 66.2k/66.2k [00:00<00:00, 167kB/s]\n"
     ]
    }
   ],
   "source": [
    "english = Field(sequential=True, use_vocab=True, tokenize=tokenize_eng, lower=True,init_token='<sos>',eos_token='<eos>',batch_first=True)\n",
    "german = Field(sequential=True, use_vocab=True, tokenize=tokenize_ger, lower=True,init_token='<sos>',eos_token='<eos>',batch_first=True)\n",
    "\n",
    "train_data, validation_data, test_data = Multi30k.splits(exts=('.de','.en'),fields=(german,english))\n",
    "\n",
    "english.build_vocab(train_data,max_size=10000,min_freq=2)\n",
    "german.build_vocab(train_data,max_size=10000,min_freq=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YT7d8K0uTZOx",
    "outputId": "162f8bfa-89e0-4807-e549-6199e5a05b02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english.vocab.stoi['<pad>']\n",
    "german.vocab.stoi['<pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wiIiIfozhEmy"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building and some helper functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4_-vFHVhWz_s"
   },
   "outputs": [],
   "source": [
    "def validation_loss(model,validation_iterator):\n",
    "    epoch_loss = []\n",
    "    for batch in validation_iterator:\n",
    "        batch_loss = []\n",
    "        source = batch.src\n",
    "        target = batch.trg   #target = encseq_len, batch\n",
    "            #print(target.shape)\n",
    "        batch_size = source.shape[0]\n",
    "        enc,out = model(source,target[:,:-1])   # out = dec_seq_len, batch, output_size    \n",
    "            #print(out.shape)\n",
    "            #print(target.shape)    \n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        out = out.view(-1,out_vocab_size)\n",
    "        target = target[:,1:].reshape(-1)\n",
    "            #print(out.shape)\n",
    "            #print(target.shape)  \n",
    "        loss = criterion(out,target)\n",
    "        batch_loss.append(loss.item())\n",
    "        epoch_loss += batch_loss\n",
    "    return (epoch_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoder class is the block which takes source sentences , mapps their attention and applies a add and norm layer at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here , Linear layers are used for creating distinct attention heads. These will be used to calculate attention outputs and these outputs will be concatenated . Here , number of heads were kept 4 to obtained the best results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying residual connections , normalization is done. It was observed that dropout of 0.22 was giving best results over this structure.\n",
    "We tryied creating only one linear layer such that its output can be reshaped as multiple heads but making distinct heads were able to build perfect mapping between words in sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see function for calculating multihead attention are methods of Encoder and Decoder class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "ZKRdJhXXhHQz"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self,batch_size,d_model,d_k,n_dk):\n",
    "        super(Encoder,self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.d_model = d_model                 #embedding_dim\n",
    "        self.d_k = d_k                         #querries and keys dimension.\n",
    "        self.n_dk = n_dk\n",
    "\n",
    "        self.dropout = nn.Dropout(0.22)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "\n",
    "        self.WQ1 =  nn.Linear(d_model,d_k)\n",
    "        self.WK1 = nn.Linear(d_model,d_k)\n",
    "        self.WV1 = nn.Linear(d_model,d_k)\n",
    "\n",
    "        self.WQ2 =  nn.Linear(d_model,d_k)\n",
    "        self.WK2 = nn.Linear(d_model,d_k)\n",
    "        self.WV2 = nn.Linear(d_model,d_k)\n",
    "\n",
    "        self.WQ3 =  nn.Linear(d_model,d_k)\n",
    "        self.WK3 = nn.Linear(d_model,d_k)\n",
    "        self.WV3 = nn.Linear(d_model,d_k)\n",
    "\n",
    "        self.WQ4 =  nn.Linear(d_model,d_k)\n",
    "        self.WK4 = nn.Linear(d_model,d_k)\n",
    "        self.WV4 = nn.Linear(d_model,d_k)\n",
    "\n",
    "        \n",
    "        self.W0 = nn.Linear(n_dk*d_k,d_model)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.ff_enc1 = nn.Linear(d_model,d_model*2)\n",
    "        self.ff_enc2 = nn.Linear(d_model*2,d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def multihead(self,x,mask):\n",
    "        q1 = self.WQ1(x)\n",
    "        k1 = self.WK1(x)\n",
    "        v1 = self.WV1(x)\n",
    "\n",
    "        q2 = self.WQ2(x)\n",
    "        k2 = self.WK2(x)\n",
    "        v2 = self.WV2(x)\n",
    "\n",
    "        q3 = self.WQ3(x)\n",
    "        k3 = self.WK3(x)\n",
    "        v3 = self.WV3(x)\n",
    "\n",
    "        q4 = self.WQ4(x)\n",
    "        k4 = self.WK4(x)\n",
    "        v4 = self.WV4(x)\n",
    "        \n",
    "        z1=torch.matmul(self.softmax((torch.matmul(q1,torch.transpose(k1,1,2))/(self.d_k**0.5)).masked_fill(mask==False,-1e10)),v1)\n",
    "        z2=torch.matmul(self.softmax((torch.matmul(q2,torch.transpose(k2,1,2))/(self.d_k**0.5)).masked_fill(mask==False,-1e10)),v2)\n",
    "        z3=torch.matmul(self.softmax((torch.matmul(q3,torch.transpose(k3,1,2))/(self.d_k**0.5)).masked_fill(mask==False,-1e10)),v3)\n",
    "        z4=torch.matmul(self.softmax((torch.matmul(q4,torch.transpose(k4,1,2))/(self.d_k**0.5)).masked_fill(mask==False,-1e10)),v4)\n",
    "\n",
    "        z = torch.cat((z1,z2,z3,z4),dim=-1)\n",
    "        z = self.W0(z)\n",
    "        return (z)\n",
    "\n",
    "    def forward(self,x,mask):\n",
    "          \n",
    "        x = self.dropout(self.multihead(x,mask)) + x\n",
    "        x = self.norm1(x)\n",
    "        x = self.dropout(self.relu(self.ff_enc2(self.dropout(self.relu(self.ff_enc1(x)))))) + x\n",
    "        x = self.norm2(x)\n",
    "        \n",
    "        return (x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decoder block takes target sentence embeddings ,finds self attention , finds attention with encoder's last layer, and then feed forward layer. After every operation, residual connection is obtained and layer normalization is applied. Here also distict heads were giving good results. Number of heads is kept 4 to obtain best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8taHGlva50rR"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "  \n",
    "    def __init__(self,batch_size,d_model,d_k,n_d_k):\n",
    "        super(Decoder,self).__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.d_model = d_model                 #embedding_dim\n",
    "        self.d_k = d_k                         #querries and keys dimension.\n",
    "        self.n_dk = n_dk\n",
    "\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "\n",
    "\n",
    "        self.dropout = nn.Dropout(0.22)\n",
    "        self.WQ1 =  nn.Linear(d_model,d_k)\n",
    "        self.WK1 = nn.Linear(d_model,d_k)\n",
    "        self.WV1 = nn.Linear(d_model,d_k)\n",
    "\n",
    "        self.WQ2 =  nn.Linear(d_model,d_k)\n",
    "        self.WK2 = nn.Linear(d_model,d_k)\n",
    "        self.WV2 = nn.Linear(d_model,d_k)\n",
    "\n",
    "        self.WQ3 =  nn.Linear(d_model,d_k)\n",
    "        self.WK3 = nn.Linear(d_model,d_k)\n",
    "        self.WV3 = nn.Linear(d_model,d_k)\n",
    "\n",
    "        self.WQ4 =  nn.Linear(d_model,d_k)\n",
    "        self.WK4 = nn.Linear(d_model,d_k)\n",
    "        self.WV4 = nn.Linear(d_model,d_k)\n",
    "\n",
    "        self.W0 = nn.Linear(n_dk*d_k,d_model)\n",
    "\n",
    "        self.EDWQ1 =  nn.Linear(d_model,d_k)\n",
    "        self.EDWK1 = nn.Linear(d_model,d_k)\n",
    "        self.EDWV1 = nn.Linear(d_model,d_k)\n",
    "\n",
    "        self.EDWQ2 =  nn.Linear(d_model,d_k)\n",
    "        self.EDWK2 = nn.Linear(d_model,d_k)\n",
    "        self.EDWV2 = nn.Linear(d_model,d_k)\n",
    "\n",
    "        self.EDWQ3 =  nn.Linear(d_model,d_k)\n",
    "        self.EDWK3 = nn.Linear(d_model,d_k)\n",
    "        self.EDWV3 = nn.Linear(d_model,d_k)\n",
    "\n",
    "        self.EDWQ4 =  nn.Linear(d_model,d_k)\n",
    "        self.EDWK4 = nn.Linear(d_model,d_k)\n",
    "        self.EDWV4 = nn.Linear(d_model,d_k)\n",
    "\n",
    "        self.EDW0 = nn.Linear(n_dk*d_k,d_model)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "        self.ff_dec1 = nn.Linear(d_model,2*d_model)\n",
    "        self.ff_dec2 = nn.Linear(2*d_model,d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def masked_multihead(self,x,mask):\n",
    "        q1 = self.WQ1(x)\n",
    "        k1 = self.WK1(x)\n",
    "        v1 = self.WV1(x)\n",
    "\n",
    "        q2 = self.WQ2(x)\n",
    "        k2 = self.WK2(x)\n",
    "        v2 = self.WV2(x)\n",
    "\n",
    "        q3 = self.WQ3(x)\n",
    "        k3 = self.WK3(x)\n",
    "        v3 = self.WV3(x)\n",
    "\n",
    "        q4 = self.WQ4(x)\n",
    "        k4 = self.WK4(x)\n",
    "        v4 = self.WV4(x)\n",
    "        \n",
    "        z1=torch.matmul(self.softmax((torch.matmul(q1,torch.transpose(k1,1,2))/(self.d_k**0.5)).masked_fill(mask==False,-1e10)),v1)\n",
    "        z2=torch.matmul(self.softmax((torch.matmul(q2,torch.transpose(k2,1,2))/(self.d_k**0.5)).masked_fill(mask==False,-1e10)),v2)\n",
    "        z3=torch.matmul(self.softmax((torch.matmul(q3,torch.transpose(k3,1,2))/(self.d_k**0.5)).masked_fill(mask==False,-1e10)),v3)\n",
    "        z4=torch.matmul(self.softmax((torch.matmul(q4,torch.transpose(k4,1,2))/(self.d_k**0.5)).masked_fill(mask==False,-1e10)),v4)\n",
    "\n",
    "        z = torch.cat((z1,z2,z3,z4),dim=-1)\n",
    "        z = self.W0(z)\n",
    "        return (z)\n",
    "        \n",
    "\n",
    "    def multihead(self,x,enc,mask):\n",
    "        q1 = self.EDWQ1(x)\n",
    "        k1 = self.EDWK1(enc)\n",
    "        v1 = self.EDWV1(enc)\n",
    "\n",
    "        q2 = self.EDWQ2(x)\n",
    "        k2 = self.EDWK2(enc)\n",
    "        v2 = self.EDWV2(enc)\n",
    "\n",
    "        q3 = self.EDWQ3(x)\n",
    "        k3 = self.EDWK3(enc)\n",
    "        v3 = self.EDWV3(enc)\n",
    "\n",
    "        q4 = self.EDWQ4(x)\n",
    "        k4 = self.EDWK4(enc)\n",
    "        v4 = self.EDWV4(enc)\n",
    "        \n",
    "        # print(q1.shape,k1.shape)\n",
    "        z1 = torch.matmul(q1,torch.transpose(k1,1,2))/(self.d_k**0.5)\n",
    "        z1=torch.matmul(self.softmax(z1.masked_fill(mask==False,-1e10)),v1)\n",
    "        z2=torch.matmul(self.softmax((torch.matmul(q2,torch.transpose(k2,1,2))/(self.d_k**0.5)).masked_fill(mask==False,-1e10)),v2)\n",
    "        z3=torch.matmul(self.softmax((torch.matmul(q3,torch.transpose(k3,1,2))/(self.d_k**0.5)).masked_fill(mask==False,-1e10)),v3)\n",
    "        z4=torch.matmul(self.softmax((torch.matmul(q4,torch.transpose(k4,1,2))/(self.d_k**0.5)).masked_fill(mask==False,-1e10)),v4)\n",
    "\n",
    "        z = torch.cat((z1,z2,z3,z4),dim=-1)\n",
    "        z = self.EDW0(z)\n",
    "        return (z)\n",
    "\n",
    "    def forward(self,x,enc,trg_mask,src_mask):\n",
    "        \n",
    "        x = self.dropout(self.masked_multihead(x,trg_mask)) + x\n",
    "        x = self.norm1(x)\n",
    "        x = self.dropout(self.multihead(x,enc,src_mask)) + x\n",
    "        x = self.norm2(x)\n",
    "        x = self.dropout(self.relu(self.ff_dec2(self.dropout(self.relu(self.ff_dec1(x)))))) + x\n",
    "        x = self.norm3(x)\n",
    "        return (x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformer block takes source and target encodings as input , fetches their embeddings , add seperate positional embeddings and pass source through Encoder and target, output of Encoder's last layer through Decoder. Within Transformer class , you can create multiple layers of encoder and decoder and stack them on top of each othe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, Embeddings are not part of Encoding or decoding. Also mask creating fuctions are methods of Transformer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fnOBIDJA437n"
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self,batch_size,in_vocab_size,out_vocab_size,d_model,d_k,n_dk,device):\n",
    "        super(Transformer,self).__init__()\n",
    "        self.in_vocab_size = in_vocab_size     #input vocab size\n",
    "        self.out_vocab_size = out_vocab_size     #input vocab size\n",
    "        self.batch_size = batch_size\n",
    "        self.d_k = d_k\n",
    "        self.d_model = d_model\n",
    "        self.device = device\n",
    "        self.n_dk = n_dk\n",
    "\n",
    "        self.enc_embeddings = nn.Embedding(in_vocab_size,d_model)\n",
    "        self.dec_embeddings = nn.Embedding(out_vocab_size,d_model)\n",
    "        self.pe_embeddings_enc = nn.Embedding(100,d_model)\n",
    "        self.pe_embeddings_dec = nn.Embedding(100,d_model)\n",
    "\n",
    "        self.encoder1 = Encoder(batch_size,d_model,d_k,n_dk)\n",
    "        # self.encoder2 = Encoder(batch_size,d_model,d_k,n_dk)\n",
    "        # self.encoder3 = Encoder(batch_size,d_model,d_k,n_dk)\n",
    "        # self.encoder4 = Encoder(batch_size,d_model,d_k,n_dk)\n",
    "\n",
    "        self.decoder1 = Decoder(batch_size,d_model,d_k,n_dk)\n",
    "        # self.decoder2 = Decoder(batch_size,d_model,d_k,n_dk)\n",
    "        # self.decoder3 = Decoder(batch_size,d_model,d_k,n_dk)\n",
    "        # self.decoder4 = Decoder(batch_size,d_model,d_k,n_dk)\n",
    "\n",
    "        self.linear = nn.Linear(d_model,out_vocab_size)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def make_src_mask(self, src):                                                       # src = [batch_size, src_len]\n",
    "        src_mask = (src != 1).unsqueeze(1).to(device)   # src_mask = [batch_size, 1, src_len]\n",
    "        return src_mask\n",
    "\n",
    "    def make_trg_mask(self, trg):                                                       # trg = [batch_size, trg_len]                  \n",
    "        trg_len = trg.shape[1] \n",
    "        pad_mask = (trg != 1).unsqueeze(1).to(device)   # pad_mask = [batch_size, 1, trg_len]\n",
    "        sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = device)).bool()   # sub_mask = [trg_len, trg_len]\n",
    "        trg_mask = pad_mask & sub_mask                                                  # trg_mask = [batch_size, trg_len, trg_len]\n",
    "        return trg_mask\n",
    "\n",
    "    def forward(self,src,trg):\n",
    "        seq_len = src.shape[1]\n",
    "        batch_size = src.shape[0]\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        enc = self.enc_embeddings(src)\n",
    "        PE1 = torch.arange(seq_len).unsqueeze(0).repeat(batch_size,1).to(device)\n",
    "        PE1 = self.pe_embeddings_enc(PE1)\n",
    "        enc = enc*(self.d_k**0.5) + PE1\n",
    "        enc = self.encoder1(enc,src_mask)\n",
    "        # enc = self.encoder2(enc,src_mask)\n",
    "        # enc = self.encoder3(enc,src_mask)\n",
    "        # enc = self.encoder4(enc,src_mask)\n",
    "\n",
    "        seq_len = trg.shape[1]\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        dec = self.dec_embeddings(trg)\n",
    "        PE2 = torch.arange(seq_len).unsqueeze(0).repeat(batch_size,1).to(device)\n",
    "        PE2 = self.pe_embeddings_dec(PE2)\n",
    "        dec = dec*(self.d_k**0.5) + PE2\n",
    "        dec = self.decoder1(dec,enc,trg_mask,src_mask)\n",
    "        # dec = self.decoder2(dec,enc,trg_mask,src_mask)\n",
    "        # dec = self.decoder3(dec,enc,trg_mask,src_mask)\n",
    "        # dec = self.decoder4(dec,enc,trg_mask,src_mask)\n",
    "        dec = self.linear(dec)\n",
    "        return (enc,dec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5bwKVF01Q1nv"
   },
   "outputs": [],
   "source": [
    "d_model = 512   # embedding dimension\n",
    "d_k = 64\n",
    "n_dk = 4\n",
    "in_vocab_size = len(german.vocab)\n",
    "out_vocab_size = len(english.vocab)\n",
    "batch_size = 128\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "learning_rate = 0.0004\n",
    "epochs = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "lxzZZZNAvs3m"
   },
   "outputs": [],
   "source": [
    "#d_model=512,d_k=64,n_dk=4,batch=128,lr=0.0004,epochs=5 gave the best results till now with single layer\n",
    "# ...................................................................................................................................................................................................................................\n",
    "# epoch train loss : 2.0330910236299826  ||  time : 15.214810371398926  ||  epoch validation loss : 2.014664277434349\n",
    "# ...................................................................................................................................................................................................................................\n",
    "# epoch train loss : 1.1160743593644467  ||  time : 15.319031000137329  ||  epoch validation loss : 1.5752189457416534\n",
    "# ...................................................................................................................................................................................................................................\n",
    "# epoch train loss : 0.82381343473947  ||  time : 15.492727041244507  ||  epoch validation loss : 1.4209523051977158\n",
    "# ...................................................................................................................................................................................................................................\n",
    "# epoch train loss : 0.645236498458795  ||  time : 15.51793885231018  ||  epoch validation loss : 1.3809292763471603\n",
    "# ...................................................................................................................................................................................................................................\n",
    "# epoch train loss : 0.5199730066738465  ||  time : 15.513466835021973  ||  epoch validation loss : 1.386391267180442\n",
    "#separated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vMzqH7XddqN2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yT2gKnIxKZw-"
   },
   "outputs": [],
   "source": [
    "train_iterator, validation_iterator, test_iterator = BucketIterator.splits((train_data,validation_data,test_data),\n",
    "                                                                          batch_size=batch_size,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yt009GMjQ1rd",
    "outputId": "13ef7bea-324b-4d45-f962-c25367d1589b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 13,846,533 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "model = Transformer(batch_size,in_vocab_size,out_vocab_size,d_model,d_k,n_dk,device).to(device)\n",
    "optimizer = optim.Adam(model.parameters(),lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vZC-qwUSMm7j",
    "outputId": "004d2a2f-ab36-4daf-adab-3f0298b25b95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (enc_embeddings): Embedding(7855, 512)\n",
       "  (dec_embeddings): Embedding(5893, 512)\n",
       "  (pe_embeddings_enc): Embedding(100, 512)\n",
       "  (pe_embeddings_dec): Embedding(100, 512)\n",
       "  (encoder1): Encoder(\n",
       "    (dropout): Dropout(p=0.22, inplace=False)\n",
       "    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (WQ1): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (WK1): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (WV1): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (WQ2): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (WK2): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (WV2): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (WQ3): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (WK3): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (WV3): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (WQ4): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (WK4): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (WV4): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (W0): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "    (ff_enc1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (ff_enc2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (decoder1): Decoder(\n",
       "    (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.22, inplace=False)\n",
       "    (WQ1): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (WK1): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (WV1): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (WQ2): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (WK2): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (WV2): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (WQ3): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (WK3): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (WV3): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (WQ4): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (WK4): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (WV4): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (W0): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (EDWQ1): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (EDWK1): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (EDWV1): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (EDWQ2): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (EDWK2): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (EDWV2): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (EDWQ3): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (EDWK3): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (EDWV3): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (EDWQ4): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (EDWK4): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (EDWV4): Linear(in_features=512, out_features=64, bias=True)\n",
       "    (EDW0): Linear(in_features=256, out_features=512, bias=True)\n",
       "    (softmax): Softmax(dim=-1)\n",
       "    (ff_dec1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (ff_dec2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (linear): Linear(in_features=512, out_features=5893, bias=True)\n",
       "  (softmax): Softmax(dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 109,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "\n",
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "mwCOjAf1Q1w3",
    "outputId": "e8a2b01b-e0bb-4dd1-c0c1-fb0f4c86ce56",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................................................................................................................................................................................................................\n",
      "epoch train loss : 2.0330910236299826  ||  time : 15.214810371398926  ||  epoch validation loss : 2.014664277434349\n",
      "...................................................................................................................................................................................................................................\n",
      "epoch train loss : 1.1160743593644467  ||  time : 15.319031000137329  ||  epoch validation loss : 1.5752189457416534\n",
      "...................................................................................................................................................................................................................................\n",
      "epoch train loss : 0.82381343473947  ||  time : 15.492727041244507  ||  epoch validation loss : 1.4209523051977158\n",
      "...................................................................................................................................................................................................................................\n",
      "epoch train loss : 0.645236498458795  ||  time : 15.51793885231018  ||  epoch validation loss : 1.3809292763471603\n",
      "...................................................................................................................................................................................................................................\n",
      "epoch train loss : 0.5199730066738465  ||  time : 15.513466835021973  ||  epoch validation loss : 1.3863912671804428\n",
      "................................................................."
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-9e6677b4889c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mepoch_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mt22\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss_lst = []\n",
    "validation_loss_lst = []\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = []\n",
    "    t1 = time.time()\n",
    "    for batch in train_iterator:\n",
    "        t11 = time.time()\n",
    "\n",
    "        source = batch.src\n",
    "        target = batch.trg   #target = batch x seqlen\n",
    "        \n",
    "        model.zero_grad()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        _,out = model(source,target[:,:-1])\n",
    "\n",
    "        out = out.view(-1,out_vocab_size)\n",
    "        target = target[:,1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(out,target)\n",
    "        epoch_loss.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        t22 = time.time()\n",
    "        print(\".\",end=\"\")\n",
    "    train_loss_lst += epoch_loss\n",
    "    t2 = time.time()\n",
    "    validation_lst = validation_loss(model,validation_iterator)\n",
    "    validation_loss_lst += validation_lst\n",
    "\n",
    "    print()\n",
    "    print(\"epoch train loss : {}  ||  time : {}  ||  epoch validation loss : {}\".format(np.mean(epoch_loss),t2-t1,np.mean(validation_lst)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9p8n4T-KSYRI"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'Transformer_sep1.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OWbqda1YS3DW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lEzHJC2DS3-J"
   },
   "source": [
    "d_model = 256   # embedding dimension\n",
    "d_k = 64\n",
    "n_dk = 6\n",
    "in_vocab_size = len(german.vocab)\n",
    "out_vocab_size = len(english.vocab)\n",
    "batch_size = 128\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "learning_rate = 0.0005\n",
    "epochs = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If dont want to train, you can load it from here also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y9Ff5rhjSZje",
    "outputId": "0b9ee13b-3ae5-41ce-9e95-e18993ec5325"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 89,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('Transformer_sep1.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "Iea_bx_iQ109",
    "outputId": "965d78b5-ec82-4309-bc07-0043703f4ff7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f15746fe490>"
      ]
     },
     "execution_count": 111,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "plt.plot(train_loss_lst)\n",
    "plt.legend(['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "rzH46qyumq6P",
    "outputId": "61a652d8-cc1f-4673-f226-be8f05edc506"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f1574598950>"
      ]
     },
     "execution_count": 112,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(validation_loss_lst)\n",
    "plt.legend(['valid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing over some random sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04jj9FnHmrBu",
    "outputId": "96172d27-9e84-41ad-ade2-cf2a4994c220"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  2,   5,  13, 287,  23,   7,  15, 110,  14, 340,  34,  21,   5, 104,\n",
      "          4,   3])\n",
      "['ein', 'mann', 'lehnt', 'sich', 'in', 'der', 'nähe', 'einer', 'belebten', 'straße', 'an', 'ein', 'gebäude', '.']\n"
     ]
    }
   ],
   "source": [
    "#sentence = 'ich habe kein interesse am spielen .' # 'i dont have intrest in playing'\n",
    "#sentence = 'ich bin heute glücklich .'  # 'i am happy today'\n",
    "#sentence = 'eine frau mochte dieses gebäude .' # 'a woman liked that building'\n",
    "#sentence = 'eines tages werde ich reich sein .'  # 'one day i will be rich'\n",
    "sentence = 'ein mann lehnt sich in der nähe einer belebten straße an ein gebäude .'  # 'a man leans against a building near a busy street .'\n",
    "#sentence = 'wer bin ich .'   # 'who am i'\n",
    "#sentence = 'ein läufer <unk> sich für ein rennen aus dem <unk> .'  #runner leaving the starting blocks of a race .\n",
    "sentence = sentence.split()\n",
    "inputs = torch.zeros([len(sentence)+2],dtype=torch.long)\n",
    "inputs[0] = 2\n",
    "inputs[-1]  = 3\n",
    "#a[1] = 1180\n",
    "for i in range(0,len(sentence)):\n",
    "\n",
    "    inputs[i+1] = german.vocab.stoi[sentence[i]]\n",
    "    \n",
    "print(inputs)\n",
    "print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rXSGesid7LkO",
    "outputId": "123cfbbc-db78-4705-8478-7876c887c0e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " a man leaning against a building near a busy street .\n"
     ]
    }
   ],
   "source": [
    "translation = ''\n",
    "trg = []\n",
    "word = '<sos>'\n",
    "word_index = 2\n",
    "count=0\n",
    "trg.append(word_index)\n",
    "src = inputs.reshape(1,-1).to(device)\n",
    "\n",
    "seq_len = src.shape[1]\n",
    "batch_size = src.shape[0]\n",
    "src_mask = model.make_src_mask(src)\n",
    "enc = model.enc_embeddings(src)\n",
    "PE1 = torch.arange(seq_len).unsqueeze(0).repeat(batch_size,1).to(device)\n",
    "PE1 = model.pe_embeddings_enc(PE1)\n",
    "enc = enc*(d_k**0.5) + PE1\n",
    "enc = model.encoder1(enc,src_mask)\n",
    "\n",
    "while (word!='<eos>' and count<=50):\n",
    "    seq_len = count+1\n",
    "    trg_mask = model.make_trg_mask(torch.tensor(trg).reshape(1,-1)).to(device)\n",
    "    dec = model.dec_embeddings(torch.tensor(trg).reshape(1,-1).to(device))    \n",
    "    PE2 = torch.arange(seq_len).unsqueeze(0).repeat(batch_size,1).to(device)\n",
    "    PE2 = model.pe_embeddings_dec(PE2)\n",
    "    dec = dec*(d_k**0.5) + PE2\n",
    "    dec = model.decoder1(dec,enc,trg_mask,src_mask)\n",
    "    dec = model.linear(dec)\n",
    "\n",
    "    word_index = torch.argmax(dec[0,-1,:]).item()\n",
    "    word = english.vocab.itos[word_index]\n",
    "    if (word!='<eos>'):\n",
    "        translation = translation + \" \" + word\n",
    "        trg.append(word_index)\n",
    "        count +=1\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u9c4JURTFdw7"
   },
   "source": [
    "## BLEU score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eg42EhcHEbHE"
   },
   "outputs": [],
   "source": [
    "out = model(inputs.reshape(1,-1).to(device),torch.tensor([[word_index]]).to(device))\n",
    "out = model.softmax(out)\n",
    "word_index = torch.argmax(out).item()\n",
    "word = english.vocab.itos[word_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Q9VrI90sFNSN",
    "outputId": "b4706bea-cff3-49e2-8029-3dfa6ebdcf81"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7O2M8M01Fs4R"
   },
   "outputs": [],
   "source": [
    "def encodings(src,trg):\n",
    "    src_enc = torch.zeros([len(src)+2],dtype=torch.long)\n",
    "    trg_enc = torch.zeros([len(trg)+2],dtype=torch.long)\n",
    "    src_enc[0] = 2\n",
    "    src_enc[-1] = 3\n",
    "    trg_enc[0] = 2\n",
    "    trg_enc[-1] = 3\n",
    "    for i in range(len(src)):\n",
    "        src_enc[i+1] = german.vocab.stoi[src[i]]\n",
    "    for i in range(len(trg)):\n",
    "        trg_enc[i+1] = english.vocab.stoi[trg[i]]\n",
    "    return(src_enc,trg_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PpC45IP_Fs-g"
   },
   "outputs": [],
   "source": [
    "from torchtext.data.metrics import bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AnxvwA-vFtDC",
    "outputId": "c3e3ce4d-ad2d-40fd-b220-94a81f2d58ab"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "predicted_target = []\n",
    "target = []\n",
    "for n,i in enumerate(test_data):\n",
    "    src = vars(test_data[n])['src']\n",
    "    t = vars(test_data[n])['trg']\n",
    "\n",
    "    src_enc,trg_enc = encodings(src,t)\n",
    "    inputs = torch.tensor(src_enc)\n",
    "\n",
    "\n",
    "    translation = []\n",
    "    trg = []\n",
    "    word = '<sos>'\n",
    "    word_index = 2\n",
    "    count=0\n",
    "    trg.append(word_index)\n",
    "    src = inputs.reshape(1,-1).to(device)\n",
    "\n",
    "\n",
    "    seq_len = src.shape[1]\n",
    "    batch_size = src.shape[0]\n",
    "    src_mask = model.make_src_mask(src)\n",
    "    enc = model.enc_embeddings(src)\n",
    "    PE1 = torch.arange(seq_len).unsqueeze(0).repeat(batch_size,1).to(device)\n",
    "    PE1 = model.pe_embeddings_enc(PE1)\n",
    "    enc = enc*(d_k**0.5) + PE1\n",
    "    enc = model.encoder1(enc,src_mask)\n",
    "    # enc = model.encoder2(enc,src_mask)\n",
    "    # enc = model.encoder3(enc,src_mask)\n",
    "    # enc = model.encoder4(enc,src_mask)\n",
    "\n",
    "    while (word!='<eos>' and count<=50):\n",
    "        seq_len = count+1\n",
    "        trg_mask = model.make_trg_mask(torch.tensor(trg).reshape(1,-1)).to(device)\n",
    "        dec = model.dec_embeddings(torch.tensor(trg).reshape(1,-1).to(device))    \n",
    "        PE2 = torch.arange(seq_len).unsqueeze(0).repeat(batch_size,1).to(device)\n",
    "        PE2 = model.pe_embeddings_dec(PE2)\n",
    "        dec = dec*(d_k**0.5) + PE2\n",
    "        dec = model.decoder1(dec,enc,trg_mask,src_mask)\n",
    "        # dec = model.decoder2(dec,enc,trg_mask,src_mask)\n",
    "        # dec = model.decoder3(dec,enc,trg_mask,src_mask)\n",
    "        # dec = model.decoder4(dec,enc,trg_mask,src_mask)\n",
    "        dec = model.linear(dec)\n",
    "\n",
    "        word_index = torch.argmax(dec[0,-1,:]).item()\n",
    "        word = english.vocab.itos[word_index]\n",
    "        if (word!='<eos>'):\n",
    "            translation.append(word)\n",
    "            trg.append(word_index)\n",
    "            count +=1\n",
    "\n",
    "    target.append([t])\n",
    "    predicted_target.append(translation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HLms8wG_FtGx",
    "outputId": "169b9ccd-0217-4697-cfac-edf595e2bbbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score on Testing Data: 32.82\n"
     ]
    }
   ],
   "source": [
    "bscore = bleu_score(predicted_target, target)\n",
    "print(f\"BLEU score on Testing Data: {bscore*100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BLEU score of 32.82 was achieved over test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some sentences and predicted translations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kr6bdMRbSvJ_",
    "outputId": "7007b76f-8942-4409-878a-0aa0180dae2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'man', 'in', 'an', 'orange', 'hat', ',', 'orange', 'and', 'white', '<unk>', '.']\n",
      "[['a', 'man', 'in', 'an', 'orange', 'hat', 'starring', 'at', 'something', '.']]\n",
      "\n",
      "['a', 'boston', '<unk>', 'terrier', 'runs', 'over', 'grass', 'in', 'front', 'of', 'a', 'white', 'fence', '.']\n",
      "[['a', 'boston', 'terrier', 'is', 'running', 'on', 'lush', 'green', 'grass', 'in', 'front', 'of', 'a', 'white', 'fence', '.']]\n",
      "\n",
      "['a', 'girl', 'in', 'a', 'karate', 'uniform', 'is', 'doing', 'a', 'trick', '.']\n",
      "[['a', 'girl', 'in', 'karate', 'uniform', 'breaking', 'a', 'stick', 'with', 'a', 'front', 'kick', '.']]\n",
      "\n",
      "['five', 'people', 'in', 'winter', 'jackets', 'with', 'helmets', 'standing', 'in', 'the', 'snow', 'with', 'helmets', 'in', 'the', 'background', '.']\n",
      "[['five', 'people', 'wearing', 'winter', 'jackets', 'and', 'helmets', 'stand', 'in', 'the', 'snow', ',', 'with', 'snowmobiles', 'in', 'the', 'background', '.']]\n",
      "\n",
      "['people', 'fixing', 'the', 'roof', 'of', 'a', 'house', '.']\n",
      "[['people', 'are', 'fixing', 'the', 'roof', 'of', 'a', 'house', '.']]\n",
      "\n",
      "['a', 'man', 'in', 'a', 'bright', 'yellow', 'and', 'a', 'group', 'of', 'men', 'in', 'a', 'dark', 'dress', 'are', 'standing', 'around', 'a', '<unk>', '.']\n",
      "[['a', 'man', 'in', 'light', 'colored', 'clothing', 'photographs', 'a', 'group', 'of', 'men', 'wearing', 'dark', 'suits', 'and', 'hats', 'standing', 'around', 'a', 'woman', 'dressed', 'in', 'a', 'strapless', 'gown', '.']]\n",
      "\n",
      "['a', 'group', 'of', 'people', 'standing', 'in', 'front', 'of', 'art', 'supplies', '.']\n",
      "[['a', 'group', 'of', 'people', 'standing', 'in', 'front', 'of', 'an', 'igloo', '.']]\n",
      "\n",
      "['a', 'boy', 'in', 'a', 'red', 'uniform', 'tries', 'to', 'catch', 'the', 'base', 'while', 'the', 'base', 'while', 'the', 'blue', 'uniform', 'is', 'trying', 'to', 'catch', 'him', '.']\n",
      "[['a', 'boy', 'in', 'a', 'red', 'uniform', 'is', 'attempting', 'to', 'avoid', 'getting', 'out', 'at', 'home', 'plate', ',', 'while', 'the', 'catcher', 'in', 'the', 'blue', 'uniform', 'is', 'attempting', 'to', 'catch', 'him', '.']]\n",
      "\n",
      "['a', 'guy', 'working', 'on', 'a', 'building', '.']\n",
      "[['a', 'guy', 'works', 'on', 'a', 'building', '.']]\n",
      "\n",
      "['a', 'man', 'in', 'a', 'vest', 'is', 'sitting', 'on', 'a', 'chair', 'holding', 'a', '<unk>', '.']\n",
      "[['a', 'man', 'in', 'a', 'vest', 'is', 'sitting', 'in', 'a', 'chair', 'and', 'holding', 'magazines', '.']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "  print(predicted_target[i])\n",
    "  print(target[i])\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DRUqWAM8F8Zy",
    "outputId": "f1cb78da-c6b6-4666-b950-e44f15c092f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['people', 'standing', 'in', 'front', 'of', 'a', 'building', '.']\n",
      "[['people', 'standing', 'outside', 'of', 'a', 'building', '.']]\n",
      "\n",
      "['a', 'teenage', 'girl', 'playing', 'a', 'trumpet', 'in', 'the', 'field', '.']\n",
      "[['a', 'teenager', 'plays', 'her', 'trumpet', 'on', 'the', 'field', 'at', 'a', 'game', '.']]\n",
      "\n",
      "['a', 'woman', 'is', 'doing', 'a', 'flip', 'on', 'the', 'beach', '.']\n",
      "[['a', 'woman', 'does', 'a', 'somersault', 'on', 'a', 'trampoline', 'on', 'the', 'beach', '.']]\n",
      "\n",
      "['a', 'man', 'stands', 'by', 'some', 'stairs', 'in', 'a', 'bar', '.']\n",
      "[['a', 'man', 'is', 'standing', 'by', 'a', 'group', 'of', 'video', 'games', 'in', 'a', 'bar', '.']]\n",
      "\n",
      "['a', 'woman', 'uses', 'a', 'drill', 'while', 'a', 'man', 'photographs', 'them', '.']\n",
      "[['a', 'woman', 'uses', 'a', 'drill', 'while', 'another', 'man', 'takes', 'her', 'picture', '.']]\n",
      "\n",
      "['a', 'woman', 'in', 'a', 'pink', 'sweater', 'is', 'cleaning', 'a', 'green', 'apron', 'and', 'cleaning', 'a', 'table', '.']\n",
      "[['a', 'woman', 'in', 'a', 'pink', 'sweater', 'and', 'an', 'apron', ',', 'cleaning', 'a', 'table', 'with', 'a', 'sponge', '.']]\n",
      "\n",
      "['a', 'man', 'is', 'cutting', 'some', 'trees', '.']\n",
      "[['a', 'man', 'cutting', 'branches', 'of', 'trees', '.']]\n",
      "\n",
      "['a', 'group', 'of', 'asian', 'boys', 'waiting', 'at', 'the', 'grill', 'that', 'is', 'stopped', '.']\n",
      "[['group', 'of', 'asian', 'boys', 'wait', 'for', 'meat', 'to', 'cook', 'over', 'barbecue', '.']]\n",
      "\n",
      "['women', 'wearing', 'traditional', 'clothing', ',', 'are', 'playing', 'the', 'native', 'american', 'flag', '.']\n",
      "[['women', ',', 'wearing', 'traditional', 'clothing', ',', 'are', 'reenacting', 'native', 'life', '.']]\n",
      "\n",
      "['a', 'man', 'pushes', 'some', 'head', 'to', 'hit', 'a', 'man', 'and', 'face', 'down', 'from', 'behind', 'him', '.']\n",
      "[['one', 'man', 'holds', 'another', 'man', \"'s\", 'head', 'down', 'and', 'prepares', 'to', 'punch', 'him', 'in', 'the', 'face', '.']]\n",
      "\n",
      "['six', 'people', 'riding', 'bikes', 'through', 'a', 'trail', '.']\n",
      "[['six', 'people', 'ride', 'mountain', 'bikes', 'through', 'a', 'jungle', 'environment', '.']]\n",
      "\n",
      "['2', 'blond', 'girl', 'sitting', 'on', 'a', 'busy', 'area', 'in', 'a', 'busy', 'area', '.']\n",
      "[['2', 'blond', 'girls', 'are', 'sitting', 'on', 'a', 'ledge', 'in', 'a', 'crowded', 'plaza', '.']]\n",
      "\n",
      "['a', 'child', 'splashing', 'in', 'the', 'water', '.']\n",
      "[['a', 'child', 'is', 'splashing', 'in', 'the', 'water']]\n",
      "\n",
      "['three', 'people', 'sitting', 'at', 'a', 'picnic', 'table', 'in', 'front', 'of', 'a', 'building', '.']\n",
      "[['three', 'people', 'sit', 'at', 'a', 'picnic', 'table', 'outside', 'of', 'a', 'building', 'painted', 'like', 'a', 'union', 'jack', '.']]\n",
      "\n",
      "['3', 'boys', 'are', 'standing', 'in', 'swim', 'trunks', 'on', 'a', 'pier', '.']\n",
      "[['3', 'boys', 'are', 'standing', 'on', 'a', 'pier', 'in', 'their', 'bathing', 'suits', '.']]\n",
      "\n",
      "['a', '<unk>', 'hands', 'a', 'woman', 'at', 'a', 'market', 'that', 'is', 'checking', 'out', 'ice', 'cream', 'as', 'she', 'looks', 'at', 'fish', '.']\n",
      "[['an', 'employee', 'is', 'handing', 'a', 'woman', 'a', 'bag', 'while', 'she', 'is', 'browsing', 'through', 'fish', 'on', 'ice', 'at', 'a', 'street', 'market', '.']]\n",
      "\n",
      "['a', 'beautiful', 'woman', 'is', 'playing', 'a', 'harp', '.']\n",
      "[['a', 'pretty', 'woman', 'plays', 'a', 'harpsichord', '.']]\n",
      "\n",
      "['a', 'building', 'looks', 'at', 'the', 'camera', 'in', 'front', 'of', 'a', 'fence', 'behind', 'him', '.']\n",
      "[['outside', 'a', 'building', ',', 'a', 'uniformed', 'security', 'guard', 'looks', 'at', 'the', 'camera', 'from', 'behind', 'a', 'fence', '.']]\n",
      "\n",
      "['the', 'young', 'lady', 'is', 'looking', 'at', 'the', 'pizza', '.']\n",
      "[['the', 'young', 'lady', 'is', 'looking', 'at', 'the', 'pizza', '.']]\n",
      "\n",
      "['a', 'shirtless', 'man', 'is', 'standing', 'on', 'and', 'shorts', ',', 'and', 'a', 'couple', 'of', 'rocks', 'and', 'fishing', '.']\n",
      "[['a', 'shirtless', 'man', 'in', 'shorts', 'is', 'fishing', 'while', 'standing', 'on', 'some', 'rocks', '.']]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(20,40):\n",
    "    print(predicted_target[i])\n",
    "    print(target[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "id": "2zNvCfnmmrMY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "seperated of trainable PE Transformers_(1) (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
